{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main Roberta Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKgGSNomYAV+0WSgKboifq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thecrazyphysicist369/Content-Emotion-Model/blob/main/main_Roberta_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "457rGnh-rI9H"
      },
      "source": [
        "##Upload the Dataset\r\n",
        "Find the dataset **cleanData.csv** in the repository. This dataset is cleaned and pre-processed. If your dataset is not, please consider cleaning it using the **Text Preprocessing.ipynb**.*italicised text* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G847KnajqzGn"
      },
      "source": [
        "data = pd.read_csv(\"/cleanData.csv\", \r\n",
        "                   dtype={\"sentiment\": \"string\", \"content\": \"string\"}\r\n",
        "                   )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOOEOVqetBbs"
      },
      "source": [
        "##Mapping the Emotions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1jghzC8tGYf"
      },
      "source": [
        "#Map the 12+ emotions in the dataset as 12\r\n",
        "sent_to_id  = {\"empty\":0, \r\n",
        "               \"sadness\":1,\r\n",
        "               \"enthusiasm\":2,\r\n",
        "               \"neutral\":3,\r\n",
        "               \"worry\":4,\r\n",
        "                \"surprise\":5,\r\n",
        "               \"love\":6,\r\n",
        "               \"fun\":7,\r\n",
        "               \"hate\":8,\r\n",
        "               \"happiness\":9,\r\n",
        "               \"boredom\":10,\r\n",
        "               \"relief\":11,\r\n",
        "               \"anger\":12}\r\n",
        "\r\n",
        "data[\"sentiment_id\"] = data['sentiment'].map(sent_to_id)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYAsbilKtYgN"
      },
      "source": [
        "##Encode the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOq6Px1nthBj"
      },
      "source": [
        "label_encoder = LabelEncoder()\r\n",
        "integer_encoded = label_encoder.fit_transform(data.sentiment_id)\r\n",
        "\r\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\r\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\r\n",
        "Y = onehot_encoder.fit_transform(integer_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM_d5gdoti9g"
      },
      "source": [
        "##Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsA7fIZqtihe"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.clean_content,\r\n",
        "                                                    Y, \r\n",
        "                                                    random_state=1995, \r\n",
        "                                                    test_size=0.2, \r\n",
        "                                                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twQNvSf1viv8"
      },
      "source": [
        "#ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWTAlOrBwAc-"
      },
      "source": [
        "def regular_encode(texts, tokenizer, maxlen=512):\r\n",
        "    enc_di = tokenizer.batch_encode_plus(\r\n",
        "        texts, \r\n",
        "        return_attention_masks=False, \r\n",
        "        return_token_type_ids=False,\r\n",
        "        pad_to_max_length=True,\r\n",
        "        max_length=maxlen\r\n",
        "    )\r\n",
        "    \r\n",
        "    return np.array(enc_di['input_ids'])\r\n",
        "\r\n",
        "def build_model(transformer, max_len=160):\r\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\r\n",
        "    sequence_output = transformer(input_word_ids)[0]\r\n",
        "    cls_token = sequence_output[:, 0, :]\r\n",
        "    out = Dense(13, activation='softmax')(cls_token)\r\n",
        "    \r\n",
        "    model = Model(inputs=input_word_ids, outputs=out)\r\n",
        "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_eVL6zgwC3s"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "MODEL = 'roberta-base'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRvphT4dwLzY"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewNgOfd7wM_X"
      },
      "source": [
        "X_train_t = regular_encode(X_train, tokenizer, maxlen=max_len)\r\n",
        "X_test_t = regular_encode(X_test, tokenizer, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWobctKNwOJW"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((X_train_t, y_train))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(1995)\r\n",
        "    .batch(batch_size)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "valid_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((X_test_t, y_test))\r\n",
        "    .batch(batch_size)\r\n",
        "    .cache()\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWO2AB-hwPVe"
      },
      "source": [
        "transformer_layer = TFAutoModel.from_pretrained(MODEL)\r\n",
        "model_roberta_base = build_model(transformer_layer, max_len=max_len)\r\n",
        "model_roberta_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcRbAx4gwQ4K"
      },
      "source": [
        "n_steps = X_train.shape[0] // batch_size\r\n",
        "model_roberta_base.fit(train_dataset,steps_per_epoch=n_steps,validation_data=valid_dataset,epochs=Epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O2K4FOSwSDA"
      },
      "source": [
        "###Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN1qy3bhwUXM"
      },
      "source": [
        "def get_sentiment2(model,text):\r\n",
        "    text = clean_text(text)\r\n",
        "    #tokenize\r\n",
        "    x_test1 = regular_encode([text], tokenizer, maxlen=max_len)\r\n",
        "    test1 = (tf.data.Dataset.from_tensor_slices(x_test1).batch(1))\r\n",
        "    #test1\r\n",
        "    sentiment = model.predict(test1,verbose = 0)\r\n",
        "    sent = np.round(np.dot(sentiment,100).tolist(),0)[0]\r\n",
        "    result = pd.DataFrame([sent_to_id.keys(),sent]).T\r\n",
        "    result.columns = [\"sentiment\",\"percentage\"]\r\n",
        "    result=result[result.percentage !=0]\r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWNv3qPnwVuC"
      },
      "source": [
        "result =get_sentiment2(model_roberta_base,\"Had an absolutely brilliant day ðŸ˜ loved seeing an old friend and reminiscing\")\r\n",
        "plot_result(result)\r\n",
        "result =get_sentiment2(model_roberta_base,\"The pain my heart feels is just too much for it to bear. Nothing eases this pain. I can’t hold myself back. I really miss you\")\r\n",
        "plot_result(result)\r\n",
        "result =get_sentiment2(model_roberta_base,\"I hate this game so much,It make me angry all the time \")\r\n",
        "plot_result(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}